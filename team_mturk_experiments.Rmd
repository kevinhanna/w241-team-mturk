---
title: "Team mTurk - Motivating Quality Work"
author: "Kevin Hanna, Kevin Stone, Changjing Zhao"
output: 
    github_document: 
      toc: true
      df_print: kable
    pdf_document: 
      toc: true
      df_print: kable
      highlight: tango
    html_document:
      toc: true
      df_print: kable
      highlight: tango
      
knit: (function(inputFile, encoding) {
  rmarkdown::render(
    inputFile, encoding = encoding,
    output_format ='github_document')
    })
  
---

## Motivating Quality Work
### What motivates crowdsourced workers to do quality work?

Our scoring metric measures the accuracy of the bounding box by calculating the euclidean distance of the Turkers bounds to the correct bounding.
Therefor a **lower score is better**.  When the treatment should cause a negative reaction, the score should increase if our hypothesis is correct.


```{r setup, include=FALSE}
library(data.table)
library(dplyr)
library(rjson)
library(pwr)
library(stargazer)
library(knitr)
```

```{r load_data, echo=FALSE}
# Read in all the data, we'll use the 'experiment_no' to pull the results from each experiment. 
d <- fread("./data/experiment_all/experiment_results.csv")

```

```{r data_cleanup, echo=FALSE}

# None of our experiments required creating multiple bounding boxes on a single image.
# We are assuming the extra bounding boxes are mistakes and taking the better score.
remove_extra_bounding_boxes <- function(d) {
  good_scores <- d[,  .(bounding_box_score = min(bounding_box_score), count = .N), keyby=.(WorkerId, ImageId, experiment_no, in_treatment)] %>% .[count<2, ]
  d[good_scores, on=.(WorkerId, ImageId, experiment_no, bounding_box_score, in_treatment)]
}

d <- remove_extra_bounding_boxes(d)

```

### Our Experiments


1. Pilot - Bound 20 images with negative treatment (Government Surveillance)
2. Pilot - Bound a single image with negative treatment (Government Surveillance)
3. Experiment - Bound a single image with positive treatment (Potential future work)
4. Experiment - Increase subjects for experiment 3
5. Experiment - Bound a single image with negative treatment, reward 2 cents (Threat of not paying for poor performance)
6. Experiment - Bound a single image with negative treatment, increased reward to 5 cents (Threat of not paying for poor performance)

```{r data_summary, echo=FALSE}
kable(
  d[, .(count=.N, mean_score=mean(bounding_box_score, na.rm=T), std_dev=sd(bounding_box_score, na.rm=T)), keyby=.(experiment_no, is_pilot, in_treatment)],
  caption = "Experiment Data Summary"
)
```


### Experiment 1, our first pilot

For our pilot, we gave the Turkers a negative treatment and asked that they draw a single bounding box on each of 20 images.  We first collected some information about the subject through a survey and then randomly assigned those subjects to treatment and control.  Our primary goal was to understand how our scoring scheme worked, gauge level of variance we should expect in future experiments and test if our covariates collected from our survey were helpful.  We had high attrition and due to a misunderstanding of the Mechanical Turk platform, our assignments to treatment and control failed and we ended up with Turkers not in our experiment in our results, and many ended up in both treatment and control.

We were not able to trust any ATE, but we could at least see the variance, which was exceptionally high.

```{r plot_experiment_1, echo=FALSE}
# Block the results by user taking their mean score
worker_mean_score <- d[experiment_no==1, .(mean_worker_score = mean(bounding_box_score), in_treatment = as.integer(median(in_treatment))), keyby=WorkerId]

dev_null <- worker_mean_score[, plot(mean_worker_score, col=(in_treatment+1))]
dev_null <- worker_mean_score[, plot(log(mean_worker_score), col=(in_treatment+1))]

```


```{r experiment_1_summary, echo=FALSE}

kable(summary(worker_mean_score[, .(mean_worker_score)]))
kable(worker_mean_score[, .(mean_score=mean(mean_worker_score, na.rm=T), std_dev=sd(mean_worker_score, na.rm=T)), keyby=.(in_treatment)])

```


```{r}
#TODO Gauge if effort decreases with more HITTs
```


### Experiment 2, our second pilot

With the first pilot behind us, we decided we needed to focus on increasing our statistical power and hypothesized that having more subjects with fewer experiments would provide more statistical power. 



```{r plot_experiment_2, echo=FALSE}
dev_null <- d[experiment_no==2, plot(bounding_box_score, col=(in_treatment+1))]
dev_null <- d[experiment_no==2, plot(log(bounding_box_score), col=(in_treatment+1))]
```


```{r experiment_2_summary, echo=FALSE}
summary(d[experiment_no==2, .(bounding_box_score)])
```

```{r experiment_2_summary_groups, echo=FALSE}

kable(d[experiment_no==2, .(mean_score=mean(bounding_box_score, na.rm=T), std_dev=sd(bounding_box_score, na.rm=T)), keyby=.(in_treatment)])
```





Even with a p-value of 0.655, this was progress.  Our coefficient for in treatment was still more likely due to random noise than not.  

#### 2.1 Power Test



```{r experiment_2_power_test, echo=FALSE}

e2_ate = d[experiment_no==2 & in_treatment == 1, mean(bounding_box_score, na.rm=T)] - d[experiment_no==2 & in_treatment == 0, mean(bounding_box_score, na.rm=T)]
e2_sd = d[experiment_no==2, sd(bounding_box_score, na.rm=T)]


power.t.test(delta=e2_ate, 
             sd=e2_sd, 
             sig.level = 0.05,
             power = 0.80,
             alternative = "one.sided",
             n = NULL)


```

To achieve the statistical power of 0.8 at the 0.05 confidence-level with the variance we had in this experiement, we would require nearly 5,800 subjects in both control and treatment.  

#### 2.2 Analysis

With this pilot, the only covariate we had was the amount of time each Turker spent on the task. And working time acts as a control explaining away some of the variance reducing the p-value for our target feature from 0.45 to 0.39.  

```{r experiment_2_regression, echo=FALSE, results='asis'}
e2_mod_1 <- d[experiment_no==2, lm(bounding_box_score ~ in_treatment)]
e2_mod_2 <- d[experiment_no==2, lm(bounding_box_score ~ in_treatment+WorkTimeInSeconds)]

stargazer(e2_mod_1,  e2_mod_2,
          type = 'text', header = FALSE, table.placement = 'h', report=('vc*p'),
          add.lines = list(c("Data Subset", "All", "All", "$x==1$")))
```


```{r experiment_2_regression_time, echo=FALSE, results='asis'}
e2_mod_3 <- d[experiment_no==2, lm(WorkTimeInSeconds ~ in_treatment)]
#e2_mod_2 <- d[experiment_no==2, lm(bounding_box_score ~ in_treatment+WorkTimeInSeconds)]

stargazer(e2_mod_3,  
          type = 'text', header = FALSE, table.placement = 'h', report=('vc*p'),
          add.lines = list(c("Data Subset", "All", "All", "$x==1$")))
```

#### 2.3 Learnings from our second experiment.

The estimated 11,600 subjects required to achieve the statistical power we needed was far too many, 
With a p-value of 0.389, even with the 11,600 subjects, we weren't likely to find a statistically significant ATE.  We need to change our experiment and collect more covariates. 



### Experiment 3, incentive of future work.  

In both of our pilots, we used a treatment which we hypothesized would cause the Turkers in treatment to work less hard, and the ATE was positive, which in our scoring means the bounding was less accurate.  We also wanted to test if a positive treatment would have a larger ATE, so the Turkers in treatment were told we were looking for Turkers to perform some future work with the hypothesis that if the Turkers though of the task as a test with the incentive of future work they would try harder.  So we ran a small experiment to test this theory.

#### 3.1 Simple regression analysis

```{r}
e3_mod_1 <- d[experiment_no==3, lm(bounding_box_score ~ in_treatment)]

stargazer(e3_mod_1, e2_mod_1,
          type = 'text', header = FALSE, table.placement = 'h', report=('vc*p'),
          add.lines = list(c("Data Subset", "All", "All", "$x==1$")))
```

The first look was disappointing, the last p-value had gone up from 0.45 in the previous experiment to 0.463 in this, but we only used a quarter the number of subjects,and  having that many fewer subjects could easily increase the probability that treatment and control look the same. 

#### 3.2 Analysis with covariates

In this experiment we asked the Turkers to answer some questions about the device they were using, their experience doing these types of tasks and some demographic info. 

```{r}
e3_mod_2 <- d[experiment_no==3, lm(bounding_box_score ~ in_treatment+factor(monitor, exclude=NA))]
e3_mod_3 <- d[experiment_no==3, lm(bounding_box_score ~ in_treatment+factor(didbf, exclude=NA))]
e3_mod_4 <- d[experiment_no==3, lm(bounding_box_score ~ in_treatment+factor(age, exclude=NA))]
e3_mod_5 <- d[experiment_no==3, lm(bounding_box_score ~ in_treatment+factor(edu, exclude=NA))]
e3_mod_6 <- d[experiment_no==3, lm(bounding_box_score ~ in_treatment+factor(income, exclude=NA))]


e3_mod_2 <- d[experiment_no==3, lm(bounding_box_score ~ in_treatment+as.factor(monitor))]
e3_mod_3 <- d[experiment_no==3, lm(bounding_box_score ~ in_treatment+as.factor(didbf))]
e3_mod_4 <- d[experiment_no==3, lm(bounding_box_score ~ in_treatment+as.factor(age))]
e3_mod_5 <- d[experiment_no==3, lm(bounding_box_score ~ in_treatment+as.factor(edu))]
e3_mod_6 <- d[experiment_no==3, lm(bounding_box_score ~ in_treatment+as.factor(income))]

stargazer(e3_mod_1, e3_mod_2, e3_mod_3, e3_mod_4, e3_mod_5, e3_mod_6, 
          type = 'text', header = FALSE, table.placement = 'h', report=('vc*p'),
          add.lines = list(c("Data Subset", "All", "All", "$x==1$")))
```

The only covariate which seemed to act as any type of control was the education question, though it wasn't very significant.  However, all of the coeffecients for the screensize question were negative, and by a fairly significant ammount.  The baseline value was cellphone, which can be significantly smaller than all the other types of screens.  So we tested that on its own.
```{r experiment_3_regression_cell, echo=FALSE, results='asis'}
e3_mod_7 <- d[experiment_no==3, lm(bounding_box_score ~ in_treatment+(monitor=="cellphone"))]

stargazer(e3_mod_7, 
          type = 'text', header = FALSE, table.placement = 'h', report=('vc*p'),
          add.lines = list(c("Data Subset", "All", "All", "$x==1$")))
```

```{r experiment_3_regression_time, echo=FALSE, results='asis'}
e3_mod_3 <- d[experiment_no==3, lm(WorkTimeInSeconds ~ in_treatment)]
#e2_mod_2 <- d[experiment_no==2, lm(bounding_box_score ~ in_treatment+WorkTimeInSeconds)]

stargazer(e3_mod_3, e2_mod_3,
          type = 'text', header = FALSE, table.placement = 'h', report=('vc*p'),
          add.lines = list(c("Data Subset", "All", "All", "$x==1$")))
```

#### 3.1 Power Test
```{r}

e3_ate = d[experiment_no==3 & in_treatment == 1, mean(bounding_box_score, na.rm=T)] - d[experiment_no==3 & in_treatment == 0, mean(bounding_box_score, na.rm=T)]

e3_sd = d[experiment_no==3, sd(bounding_box_score, na.rm=T)]


power.t.test(delta=e3_ate, 
             sd=e3_sd, 
             sig.level = 0.05,
             power = 0.80,
             alternative = "one.sided",
             n = NULL)


```

### Experiment 4, More data

#TODO demographic info show how random it is.
```{r}
e4_mod_1 <- d[experiment_no %in% c(3,4), lm(bounding_box_score ~ in_treatment)]
summary(e4_mod_1)

#d[experiment_no %in% c(1), .(sd(bounding_box_score)), keyby=WorkerId]
```


```{r experiment_4_regression, echo=FALSE, results='asis'}
e4_mod_4 <- d[experiment_no %in% c(3,4), lm(WorkTimeInSeconds ~ in_treatment)]

stargazer(e4_mod_4, e3_mod_3, e2_mod_3,
          type = 'text', header = FALSE, table.placement = 'h', report=('vc*p'),
          add.lines = list(c("Data Subset", "All", "All", "$x==1$")))
```

```{r}
#e4_mod_2 <- d[experiment_no %in% c(3,4), lm(bounding_box_score ~ in_treatment+is_mobile+tried=(monitor=="" &	mousetrackpad==""))]
#summary(e4_mod_2)

e4_mod_2 <- d[experiment_no %in% c(3,4), .(tried=as.numeric(monitor=="" &	mousetrackpad==""), bounding_box_score, in_treatment, is_mobile, WorkTimeInSeconds)] %>% 
  .[, lm(bounding_box_score ~ in_treatment+is_mobile+tried)]
summary(e4_mod_2)

e4_mod_2 <- d[experiment_no %in% c(3,4), .(tried=as.numeric(mousetrackpad==""), bounding_box_score, in_treatment, is_mobile, Reward)] %>% 
  .[, lm(bounding_box_score ~ in_treatment+is_mobile+tried)]
summary(e4_mod_2)

e4_mod_2 <- d[experiment_no %in% c(3,4), lm(bounding_box_score ~ in_treatment+is_mobile)]
summary(e4_mod_2)
```
```{r, results='asis'}
stargazer(e3_mod_1, e4_mod_1, 
          type = 'text', header = FALSE, table.placement = 'h', 
          add.lines = list(c("Data Subset", "All", "All", "$x==1$")))
```


```{r, results='asis'}
stargazer(e4_mod_1, e4_mod_2, 
          type = 'text', header = FALSE, table.placement = 'h', 
          add.lines = list(c("Data Subset", "All", "All", "$x==1$")))
```


```{r, results='asis'}
e4_mod_3 <- d[experiment_no %in% c(3,4), lm(bounding_box_score ~ in_treatment+factor(monitor, exclude=c(NA)))]
e4_mod_4 <- d[experiment_no %in% c(3,4), lm(bounding_box_score ~ in_treatment+factor(didbf, exclude=c(NA)))]
e4_mod_5 <- d[experiment_no %in% c(3,4), lm(bounding_box_score ~ in_treatment+factor(age, exclude=NA))]
e4_mod_6 <- d[experiment_no %in% c(3,4), lm(bounding_box_score ~ in_treatment+factor(edu, exclude=NA))]
e4_mod_7 <- d[experiment_no %in% c(3,4), lm(bounding_box_score ~ in_treatment+factor(income, exclude=NA))]

stargazer(e4_mod_3, e4_mod_4, e4_mod_5, e4_mod_6, e4_mod_7,
          type = 'text', header = FALSE, table.placement = 'h', 
          add.lines = list(c("Data Subset", "All", "All", "$x==1$")))

```




#### 4.1 Power Test
```{r}

e4_ate = d[experiment_no %in% c(3, 4) & in_treatment == 1, mean(bounding_box_score, na.rm=T)] - d[experiment_no %in% c(3, 4) & in_treatment == 0, mean(bounding_box_score, na.rm=T)]

e4_sd = d[experiment_no %in% c(3, 4), sd(bounding_box_score, na.rm=T)]


power.t.test(delta=abs(e4_ate), 
             sd=e4_sd, 
             sig.level = 0.05,
             power = 0.80,
             alternative = "one.sided",
             n = NULL)
```

```{r}

power_curve <- function(x) {
  result = c()

  for (i in 1:length(x)) {
    new_n <- power.t.test(delta=abs(e4_ate), 
             sd=e4_sd, 
             sig.level = 0.05,
             power = NULL,
             alternative = "one.sided",
             n = x[i])["power"]
    
    result <- c(result, new_n)
  }
  
  return(result)
}

sig_curve <- function(x) {
  result = c()

  for (i in 1:length(x)) {
    new_n <- power.t.test(delta=abs(e4_ate), 
             sd=e4_sd, 
             sig.level = NULL,
             power = 0.8,
             alternative = "one.sided",
             n = x[i])["sig.level"]
    
    result <- c(result, new_n)
  }
  
  return(result)
}

delta_curve <- function(x) {
  result = c()

  for (i in 1:length(x)) {
    new_n <- power.t.test(delta=x[i], 
             sd=e4_sd, 
             sig.level = 0.05,
             power = 0.8,
             alternative = "one.sided",
             n = NULL)["n"]
    
    result <- c(result, new_n)
  }
  
  return(result)
}
curve(power_curve(x), 10, 1000)
#curve(sig_curve(x), 10, 1000)
#curve(delta_curve(x), 5, 20)

```


### Experiment 5, threats don't work

```{r}

e5_mod_1 <- d[experiment_no == 5, lm(bounding_box_score ~ in_treatment)]
summary(e5_mod_1)
```


### Experiment 6, threats still don't work

```{r}

e6_mod_1 <- d[experiment_no == 6, lm(bounding_box_score ~ in_treatment)]
summary(e6_mod_1)
```

```{r}
e6_mod_2 <- d[experiment_no %in% c(5,6), lm(bounding_box_score ~ in_treatment+(Reward == "$0.05"))]
summary(e6_mod_2)
```